<!DOCTYPE html>
<html>
<head>
    <title>Ash AI Assistant</title>
    <link rel="stylesheet" href="{{ url_for('static', filename='css/style.css') }}">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
</head>
<body>
    <div class="container">
        <div class="ai-assistant">
            <div class="ai-circle" id="ai-circle">
                <div class="inner-circle"></div>
                <div class="audio-visualizer">
                    <div class="audio-bar"></div>
                    <div class="audio-bar"></div>
                    <div class="audio-bar"></div>
                    <div class="audio-bar"></div>
                    <div class="audio-bar"></div>
                </div>
            </div>
            <div class="status-text" id="status-text">Initializing...</div>
            <div class="system-info" id="system-info"></div>
        </div>
        
        <div class="voice-waves" id="voice-waves">
            <div class="wave"></div>
            <div class="wave"></div>
            <div class="wave"></div>
            <div class="wave"></div>
        </div>

        <div class="chat-container" id="chat-container">
            <div class="chat-messages" id="chat-messages"></div>
            <div class="chat-input-container">
                <input type="text" id="chat-input" placeholder="Type your message...">
                <button id="send-button">
                    <i class="fas fa-paper-plane"></i>
                </button>
            </div>
        </div>
    </div>

    <script>
        const aiCircle = document.getElementById('ai-circle');
        const statusText = document.getElementById('status-text');
        const systemInfo = document.getElementById('system-info');
        const voiceWaves = document.getElementById('voice-waves');
        let isListening = false;
        let isProcessing = false;
        let recognition;
        let commandRecognition;
        let speechSynthesis = window.speechSynthesis;
        let aiVoice = null;

        // Modified Initialize voice function to prioritize female voices
        function initializeVoice() {
            return new Promise((resolve) => {
                const checkVoices = () => {
                    const voices = window.speechSynthesis.getVoices();
                    if (voices.length > 0) {
                        // Priority list for female voices that sound more like Ash
                        aiVoice = voices.find(voice => 
                            voice.name.includes('Microsoft Zira') ||      // Windows female voice
                            voice.name.includes('Google UK Female') ||    // British female voice
                            voice.name.includes('Samantha') ||           // macOS female voice
                            (voice.lang === 'en-GB' && voice.name.includes('Female')) ||
                            (voice.lang === 'en-US' && voice.name.includes('Female'))
                        ) || voices[0];
                        
                        console.log('Voice initialized:', aiVoice.name);
                        resolve();
                    } else {
                        setTimeout(checkVoices, 100);
                    }
                };
                checkVoices();
            });
        }

        // Modified speak function for Ash-like voice
        function speak(text) {
            return new Promise((resolve) => {
                if (!text) {
                    resolve();
                    return;
                }

                window.speechSynthesis.cancel();
                const utterance = new SpeechSynthesisUtterance(text);
                
                if (aiVoice) {
                    utterance.voice = aiVoice;
                }
                
                utterance.lang = 'en-GB';
                utterance.pitch = 1.1;
                utterance.rate = 0.95;
                utterance.volume = 1.0;

                // Create audio context for visualization
                const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                const analyser = audioContext.createAnalyser();
                analyser.fftSize = 32;
                
                const audioBars = document.querySelectorAll('.audio-bar');
                const dataArray = new Uint8Array(analyser.frequencyBinCount);
                
                utterance.onstart = () => {
                    aiCircle.classList.add('speaking');
                    statusText.textContent = text;
                    
                    // Start visualization
                    function updateBars() {
                        if (aiCircle.classList.contains('speaking')) {
                            analyser.getByteFrequencyData(dataArray);
                            audioBars.forEach((bar, index) => {
                                const value = dataArray[index];
                                const height = value ? Math.max(30, value / 255 * 100) : 30;
                                bar.style.height = `${height}%`;
                            });
                            requestAnimationFrame(updateBars);
                        }
                    }
                    updateBars();
                };
                
                utterance.onend = () => {
                    aiCircle.classList.remove('speaking');
                    audioBars.forEach(bar => {
                        bar.style.height = '30%';
                    });
                    resolve();
                };

                utterance.onerror = () => {
                    aiCircle.classList.remove('speaking');
                    audioBars.forEach(bar => {
                        bar.style.height = '30%';
                    });
                    resolve();
                };

                setTimeout(() => {
                    window.speechSynthesis.speak(utterance);
                }, 100);
            });
        }

        // Add this function for voice recognition initialization
        function initializeVoiceRecognition() {
            if ('webkitSpeechRecognition' in window) {
                recognition = new webkitSpeechRecognition();
                recognition.continuous = true;
                recognition.interimResults = true;

                commandRecognition = new webkitSpeechRecognition();
                commandRecognition.continuous = false;
                commandRecognition.interimResults = false;

                recognition.onstart = () => {
                    console.log('Wake word detection started');
                    isListening = true;
                };

                recognition.onresult = function(event) {
                    const transcript = Array.from(event.results)
                        .map(result => result[0].transcript.toLowerCase())
                        .join('');

                    if (transcript.includes('hey Ash') || transcript.includes('Ash')) {
                        startListeningForCommand();
                    }
                };

                recognition.onend = function() {
                    if (!isProcessing) {
                        recognition.start();
                    }
                };

                commandRecognition.onresult = function(event) {
                    const command = event.results[0][0].transcript;
                    processCommand(command);
                };

                commandRecognition.onend = function() {
                    if (!isProcessing) {
                        resetToWakeWordMode();
                    }
                };

                // Start listening for wake word
                recognition.start();
            } else {
                console.error('Speech recognition not supported');
                statusText.textContent = 'Speech recognition not supported in this browser';
            }
        }

        // Modified processCommand function with better state management
        function processCommand(command) {
            isProcessing = true;
            aiCircle.classList.add('processing');
            voiceWaves.classList.remove('active');
            statusText.textContent = "Processing...";

            // Stop both recognitions during processing
            if (recognition) {
                recognition.stop();
            }
            if (commandRecognition) {
                commandRecognition.stop();
            }

            fetch('/process', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({ command: command })
            })
            .then(response => response.json())
            .then(async data => {
                statusText.textContent = data.result;
                await speak(data.result);
                // Wait a bit before resetting
                await new Promise(resolve => setTimeout(resolve, 500));
                resetToWakeWordMode();
            })
            .catch(async error => {
                console.error('Command processing error:', error);
                const errorMessage = "Sorry, there was an error processing your command.";
                statusText.textContent = errorMessage;
                await speak(errorMessage);
                // Wait a bit before resetting
                await new Promise(resolve => setTimeout(resolve, 500));
                resetToWakeWordMode();
            });
        }

        // Modified resetToWakeWordMode function with better state management
        function resetToWakeWordMode() {
            // First stop all ongoing recognitions
            if (recognition) {
                try {
                    recognition.stop();
                } catch (e) {
                    console.error('Error stopping recognition:', e);
                }
            }
            if (commandRecognition) {
                try {
                    commandRecognition.stop();
                } catch (e) {
                    console.error('Error stopping command recognition:', e);
                }
            }

            // Reset states
            isProcessing = false;
            isListening = false;
            
            // Reset visual elements
            aiCircle.classList.remove('active', 'processing', 'speaking');
            voiceWaves.classList.remove('active');
            statusText.textContent = 'Say "Hey Ash" or "Ash" to start';
            
            // Restart wake word detection after a longer delay
            setTimeout(() => {
                try {
                    if (!isProcessing && !isListening) {  // Double check states
                        recognition.start();
                        isListening = true;
                        console.log('Wake word detection restarted');
                    }
                } catch (e) {
                    console.error('Error restarting recognition:', e);
                    statusText.textContent = 'Error restarting voice recognition. Please refresh the page.';
                }
            }, 1000);  // Increased delay
        }

        // Modified startup sequence to handle user interaction requirement
        async function startupSequence() {
            try {
                console.log('Starting initialization...');
                
                // Initialize voice first
                await initializeVoice();
                
                aiCircle.classList.add('startup');
                
                // Fetch system info
                const response = await fetch('/system_info');
                const systemData = await response.json();
                
                // Display system info
                systemInfo.innerHTML = `
                    <div class="info-item"><i class="fas fa-microchip"></i> ${systemData.cpu}</div>
                    <div class="info-item"><i class="fas fa-memory"></i> ${systemData.memory}</div>
                    <div class="info-item"><i class="fas fa-clock"></i> ${systemData.time}</div>
                `;

                // Add a click to start button
                statusText.textContent = 'Click anywhere to start Ash AI';
                document.body.style.cursor = 'pointer';
                
                // Wait for user interaction
                await new Promise(resolve => {
                    document.body.onclick = () => {
                        document.body.onclick = null;
                        document.body.style.cursor = 'default';
                        resolve();
                    };
                });

                // Now start the voice sequence after user interaction
                const startupMessages = [
                    "Initializing Ash AI Assistant",
                    "All systems online",
                    "Voice recognition activated",
                    "activate me by saying Hey Ash or just Ash"
                ];

                for (const message of startupMessages) {
                    await speak(message);
                    await new Promise(resolve => setTimeout(resolve, 500));
                }
                
                aiCircle.classList.remove('startup');
                statusText.textContent = 'Say "Hey Ash" or "Ash" to start';
                
                // Start voice recognition
                initializeVoiceRecognition();
                
            } catch (error) {
                console.error('Startup sequence error:', error);
                statusText.textContent = 'Error during initialization. Please refresh the page.';
            }
        }

        // Modified startListeningForCommand function with better timing
        async function startListeningForCommand() {
            // Stop wake word recognition
            if (recognition) {
                recognition.stop();
            }
            
            isProcessing = true;
            aiCircle.classList.add('active');
            voiceWaves.classList.add('active');
            
            await speak("Yes?");
            statusText.textContent = "Listening...";
            
            // Longer delay before starting command recognition
            await new Promise(resolve => setTimeout(resolve, 1000));
            
            try {
                if (isProcessing) {  // Check if we're still in processing state
                    commandRecognition.start();
                }
            } catch (e) {
                console.error('Error starting command recognition:', e);
                resetToWakeWordMode();
            }
        }

        // Start the system when page loads
        window.addEventListener('load', () => {
            console.log('Page loaded, starting initialization...');
            startupSequence();
        });

        // Chat handling functions
        const chatInput = document.getElementById('chat-input');
        const sendButton = document.getElementById('send-button');
        const chatMessages = document.getElementById('chat-messages');

        function addMessage(text, isUser = false) {
            const messageDiv = document.createElement('div');
            messageDiv.className = `chat-message ${isUser ? 'user-message' : 'assistant-message'}`;
            messageDiv.textContent = text;
            chatMessages.appendChild(messageDiv);
            chatMessages.scrollTop = chatMessages.scrollHeight;
        }

        async function handleChatMessage() {
            const message = chatInput.value.trim();
            if (!message) return;
            
            chatInput.value = '';
            addMessage(message, true);
            aiCircle.classList.add('processing');
            
            try {
                const response = await fetch('/process', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({ command: message })
                });
                
                const data = await response.json();
                addMessage(data.result);
                await speak(data.result);
                
            } catch (error) {
                console.error('Error:', error);
                addMessage('Sorry, there was an error processing your message.');
            } finally {
                aiCircle.classList.remove('processing');
            }
        }

        // Add chat event listeners
        chatInput.addEventListener('keypress', (e) => {
            if (e.key === 'Enter' && chatInput.value.trim()) {
                handleChatMessage();
            }
        });

        sendButton.addEventListener('click', () => {
            if (chatInput.value.trim()) {
                handleChatMessage();
            }
        });
    </script>
</body>
</html> 